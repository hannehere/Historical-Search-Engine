"""
output_analyzer.py
Tool Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  hiá»ƒu káº¿t quáº£ output cá»§a Enhanced Search Engine
"""

from EnhancedSearchEngine import EnhancedSearchEngine
import json

def analyze_build_output():
    """PhÃ¢n tÃ­ch output khi build index"""
    print("ğŸ” PHÃ‚N TÃCH OUTPUT Cá»¦A BUILD INDEX")
    print("=" * 60)
    
    engine = EnhancedSearchEngine("data_content.json", {
        'chunking_strategy': 'hybrid',
        'chunk_size': 256,
        'overlap_size': 32,
        'use_stopwords': True,
        'tokenizer_library': 'underthesea',
        'embedding_model': 'keepitreal/vietnamese-sbert',
        'use_bm25': True,
        'use_embedding': False,  # Skip heavy model for demo
        'bm25_weight': 1.0,
        'embedding_weight': 0.0,
        'top_k_results': 5,
        'top_k_chunks_per_search': 20,
        'enable_caching': True
    })
    
    print("\nğŸ“‹ GIáº¢I THÃCH CÃC BÆ¯á»šC BUILD:")
    print("[1/4] Load documents and create chunks:")
    print("  - Äá»c file JSON chá»©a 207 documents")
    print("  - Chia má»—i document thÃ nh nhiá»u chunks nhá»")
    print("  - VÃ­ dá»¥: 'Há»“ ChÃ­ Minh.md' â†’ 101 chunks")
    
    print("\n[2/4] Tokenizing chunks:")
    print("  - Chuyá»ƒn Ä‘á»•i text thÃ nh tokens (tá»«)")
    print("  - Loáº¡i bá» stopwords (tá»« khÃ´ng quan trá»ng)")
    print("  - Chuáº©n hÃ³a tiáº¿ng Viá»‡t")
    
    print("\n[3/4] Indexing chunks:")
    print("  - Táº¡o BM25 index cho tÃ¬m kiáº¿m keyword")
    print("  - Táº¡o embeddings cho tÃ¬m kiáº¿m semantic (náº¿u enabled)")
    
    print("\n[4/4] Performance Analysis:")
    print("  - Tá»•ng sá»‘ chunks: Sá»‘ lÆ°á»£ng Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c táº¡o")
    print("  - Avg chunks/doc: Trung bÃ¬nh chunks má»—i document")
    print("  - Chunk sizes: KÃ­ch thÆ°á»›c tá»« nhá» nháº¥t Ä‘áº¿n lá»›n nháº¥t")
    
    # Build actual index Ä‘á»ƒ show real output
    print("\n" + "="*60)
    print("ğŸ”§ DEMO THá»°C Táº¾:")
    engine.build_index()
    
    return engine

def analyze_search_output(engine):
    """PhÃ¢n tÃ­ch output khi search"""
    print("\n" + "="*60)
    print("ğŸ” PHÃ‚N TÃCH OUTPUT Cá»¦A SEARCH")
    print("="*60)
    
    query = "Há»“ ChÃ­ Minh"
    
    print(f"\nğŸ“ Query: '{query}'")
    print("\nğŸ’¡ GIáº¢I THÃCH CÃC SEARCH MODE:")
    
    # Document Mode
    print("\n1ï¸âƒ£ DOCUMENT MODE:")
    print("   - TÃ¬m documents liÃªn quan nháº¥t")
    print("   - Score cao = liÃªn quan hÆ¡n")
    print("   - Best chunks count = sá»‘ chunks tá»‘t nháº¥t trong document")
    
    doc_results = engine.search(query, top_k=3, search_mode='document')
    
    print("\nğŸ“Š Káº¾T QUáº¢ DOCUMENT MODE:")
    for i, result in enumerate(doc_results, 1):
        print(f"   [{i}] File: {result['file_name']}")
        print(f"       Score: {result['score']:.3f} (cÃ ng cao cÃ ng liÃªn quan)")
        print(f"       Chunks: {result.get('best_chunks_count', 'N/A')} chunks tá»‘t nháº¥t")
        print(f"       Preview: {result.get('preview', 'N/A')[:80]}...")
    
    # Chunk Mode
    print("\n2ï¸âƒ£ CHUNK MODE:")
    print("   - TÃ¬m cÃ¡c Ä‘oáº¡n vÄƒn cá»¥ thá»ƒ")
    print("   - Cho tháº¥y chÃ­nh xÃ¡c pháº§n nÃ o cá»§a document liÃªn quan")
    print("   - Chunk type: loáº¡i Ä‘oáº¡n (section, sub_section, paragraph)")
    
    chunk_results = engine.search(query, top_k=3, search_mode='chunk')
    
    print("\nğŸ“Š Káº¾T QUáº¢ CHUNK MODE:")
    for i, result in enumerate(chunk_results, 1):
        print(f"   [{i}] File: {result['file_name']}")
        print(f"       Chunk Type: {result['chunk_type']} (loáº¡i Ä‘oáº¡n vÄƒn)")
        print(f"       Score: {result['score']:.3f}")
        print(f"       Content: {result['content'][:80].replace(chr(10), ' ')}...")
    
    # Context Mode
    print("\n3ï¸âƒ£ CONTEXT MODE:")
    print("   - TÃ¬m documents vá»›i context xung quanh")
    print("   - Total chunks: tá»•ng sá»‘ chunks liÃªn quan")
    print("   - Best chunks: sá»‘ chunks tá»‘t nháº¥t")
    
    context_results = engine.search(query, top_k=2, search_mode='context')
    
    print("\nğŸ“Š Káº¾T QUáº¢ CONTEXT MODE:")
    for i, result in enumerate(context_results, 1):
        print(f"   [{i}] File: {result['file_name']}")
        print(f"       Score: {result['score']:.3f}")
        print(f"       Best chunks: {result['best_chunks']}")
        print(f"       Total chunks: {result['total_chunks']}")
        print(f"       Content: {result['content'][:80].replace(chr(10), ' ')}...")

def analyze_scores_and_ranking():
    """Giáº£i thÃ­ch vá» scores vÃ  ranking"""
    print("\n" + "="*60)
    print("ğŸ“ˆ HIá»‚U Vá»€ SCORES VÃ€ RANKING")
    print("="*60)
    
    print("\nğŸ¯ SCORE LÃ€ GÃŒ?")
    print("   - Score = Ä‘á»™ liÃªn quan giá»¯a query vÃ  document/chunk")
    print("   - CÃ ng cao = cÃ ng liÃªn quan")
    print("   - Khoáº£ng tá»« 0.000 Ä‘áº¿n ~3.000+")
    
    print("\nğŸ”¢ CÃC THÃ€NH PHáº¦N SCORE:")
    print("   - BM25 Score: TÃ¬m kiáº¿m tá»« khÃ³a (keyword matching)")
    print("   - Embedding Score: Hiá»ƒu nghÄ©a (semantic similarity)")
    print("   - Boost Factors: TÄƒng cÆ°á»ng dá»±a trÃªn:")
    print("     â€¢ Chunk type (overview > section > paragraph)")
    print("     â€¢ Title matching (query cÃ³ trong tiÃªu Ä‘á»)")
    print("     â€¢ Position (Ä‘áº§u document quan trá»ng hÆ¡n)")
    
    print("\nğŸ“Š VÃ Dá»¤ SCORE:")
    print("   Score 2.500+: Ráº¥t liÃªn quan (exact match)")
    print("   Score 1.500-2.499: LiÃªn quan cao")  
    print("   Score 0.500-1.499: LiÃªn quan trung bÃ¬nh")
    print("   Score 0.000-0.499: LiÃªn quan tháº¥p")

def interactive_output_guide():
    """HÆ°á»›ng dáº«n sá»­ dá»¥ng interactive mode"""
    print("\n" + "="*60)
    print("ğŸ’¬ HÆ¯á»šNG DáºªN INTERACTIVE MODE")
    print("="*60)
    
    print("\nğŸ® CÃC Lá»†NH INTERACTIVE:")
    print("   - GÃµ query Ä‘á»ƒ search: 'Há»“ ChÃ­ Minh'")
    print("   - :mode document    â†’ Chuyá»ƒn sang document mode")
    print("   - :mode chunk       â†’ Chuyá»ƒn sang chunk mode") 
    print("   - :mode context     â†’ Chuyá»ƒn sang context mode")
    print("   - :explain on       â†’ Báº­t giáº£i thÃ­ch chi tiáº¿t")
    print("   - :explain off      â†’ Táº¯t giáº£i thÃ­ch")
    print("   - :stats            â†’ Xem thá»‘ng kÃª há»‡ thá»‘ng")
    print("   - :quit             â†’ ThoÃ¡t")
    
    print("\nğŸ“‹ KHI NÃ€O DÃ™NG MODE NÃ€O:")
    print("   ğŸ“„ Document Mode: TÃ¬m tÃ i liá»‡u tá»•ng quan")
    print("   ğŸ§© Chunk Mode: TÃ¬m Ä‘oáº¡n vÄƒn cá»¥ thá»ƒ")
    print("   ğŸŒ Context Mode: TÃ¬m vá»›i ngá»¯ cáº£nh xung quanh")
    
    print("\nğŸ’¡ TIPS Äá»‚ TÃŒM KIáº¾M Tá»‘T:")
    print("   âœ… DÃ¹ng tá»« khÃ³a chÃ­nh: 'Há»“ ChÃ­ Minh', 'chiáº¿n tranh'")
    print("   âœ… Káº¿t há»£p nhiá»u tá»«: 'chiáº¿n tranh Viá»‡t Nam'")
    print("   âœ… Thá»­ cÃ¡c mode khÃ¡c nhau Ä‘á»ƒ so sÃ¡nh")
    print("   âœ… DÃ¹ng :explain on Ä‘á»ƒ hiá»ƒu táº¡i sao káº¿t quáº£ Ä‘Æ°á»£c rank cao")

def create_sample_search_session():
    """Táº¡o má»™t session search máº«u"""
    print("\n" + "="*60)
    print("ğŸ¬ SESSION SEARCH MáºªU")
    print("="*60)
    
    # Simulate má»™t session thá»±c táº¿
    sample_queries = [
        ("BÃ  Triá»‡u", "document"),
        ("chiáº¿n tranh Äiá»‡n BiÃªn Phá»§", "chunk"), 
        ("NgÃ´ Quyá»n", "context")
    ]
    
    engine = EnhancedSearchEngine("data_content.json", {
        'chunking_strategy': 'semantic',
        'chunk_size': 256,
        'use_bm25': True,
        'use_embedding': False,
        'top_k_results': 2,
        'top_k_chunks_per_search': 10,
        'enable_caching': True
    })
    
    print("ğŸ”§ Building index...")
    engine.build_index()
    
    for query, mode in sample_queries:
        print(f"\nğŸ” Query: '{query}' (Mode: {mode})")
        print("-" * 40)
        
        results = engine.search(query, top_k=2, search_mode=mode)
        
        if mode == 'document':
            for i, r in enumerate(results, 1):
                print(f"[{i}] {r['file_name']} (Score: {r['score']:.3f})")
        elif mode == 'chunk':
            for i, r in enumerate(results, 1):
                print(f"[{i}] {r['file_name']} - {r['chunk_type']} (Score: {r['score']:.3f})")
        else:  # context
            for i, r in enumerate(results, 1):
                print(f"[{i}] {r['file_name']} (Score: {r['score']:.3f}, Chunks: {r['total_chunks']})")

def main():
    """Main analysis function"""
    print("ğŸ¯ HÆ¯á»šNG DáºªN Äá»ŒC HIá»‚U OUTPUT ENHANCED SEARCH ENGINE")
    print("="*70)
    
    # 1. Analyze build output
    engine = analyze_build_output()
    
    # 2. Analyze search output  
    analyze_search_output(engine)
    
    # 3. Explain scores
    analyze_scores_and_ranking()
    
    # 4. Interactive guide
    interactive_output_guide()
    
    # 5. Sample session
    create_sample_search_session()
    
    print("\n" + "="*70)
    print("âœ… HOÃ€N Táº¤T HÆ¯á»šNG DáºªN!")
    print("ğŸ’¡ BÃ¢y giá» báº¡n Ä‘Ã£ hiá»ƒu cÃ¡ch Ä‘á»c vÃ  phÃ¢n tÃ­ch output!")
    print("ğŸš€ HÃ£y thá»­ cháº¡y: python EnhancedSearchEngine.py")

if __name__ == "__main__":
    main()